{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba311076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_10840/424883077.py:17: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import regex\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import demoji\n",
    "import emoji\n",
    "from sklearn.metrics import f1_score\n",
    "demoji.download_codes()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1556c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading whitespace: Package 'whitespace' not found\n",
      "[nltk_data]     in index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('whitespace')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e381a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3766514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh   I don’t know about you Irvine b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>https://t.co/T2aD3v6dpm I bet money if i went...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh   I don’t know about you Irvine b...   \n",
       "1  1377631738692796417   https://t.co/T2aD3v6dpm I bet money if i went...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5  1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6  1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7  1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8  1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9  1362671045136809985  I’m going to sound like I have lost my marbles...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eec238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d34f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119e50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d4294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e86bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (6080, 5000)\n",
      "Test features shape: (1520, 5000)\n",
      "Train Features:\n",
      "                  \"         #        #c       #co      #cov        #v  \\\n",
      "0     0.662224  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1     0.709971  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2     0.714751  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.690168  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4     0.676085  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "6075  0.696563  0.0  0.100025  0.028605  0.028849  0.029231  0.039555   \n",
      "6076  0.683131  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6077  0.536209  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6078  0.471508  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6079  0.716027  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "           #va      #vac         &  ...   ’v  ’ve  ’ve     “    ”   ”     ️  \\\n",
      "0     0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "4     0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "...        ...       ...       ...  ...  ...  ...   ...  ...  ...  ...  ...   \n",
      "6075  0.039993  0.040083  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "6076  0.000000  0.000000  0.101968  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "6077  0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "6078  0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "6079  0.000000  0.000000  0.000000  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       ️     😂    🙏  \n",
      "0     0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  \n",
      "...   ...  ...  ...  \n",
      "6075  0.0  0.0  0.0  \n",
      "6076  0.0  0.0  0.0  \n",
      "6077  0.0  0.0  0.0  \n",
      "6078  0.0  0.0  0.0  \n",
      "6079  0.0  0.0  0.0  \n",
      "\n",
      "[6080 rows x 5000 columns]\n",
      "Test Features:\n",
      "                  \"    #   #c   #co   #cov   #v   #va   #vac    &  ...   ’v  \\\n",
      "0     0.696746  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "1     0.676864  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "2     0.636641  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "3     0.687394  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "4     0.655848  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "...        ...  ...  ...  ...   ...    ...  ...   ...    ...  ...  ...  ...   \n",
      "1515  0.684388  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "1516  0.694165  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "1517  0.689374  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "1518  0.759311  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "1519  0.722189  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  0.0  ...  0.0   \n",
      "\n",
      "      ’ve  ’ve         “        ”        ”          ️   ️     😂    🙏  \n",
      "0     0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "1     0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "2     0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "3     0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "4     0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "...   ...   ...      ...      ...       ...       ...  ...  ...  ...  \n",
      "1515  0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "1516  0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "1517  0.0   0.0  0.00000  0.00000  0.000000  0.046522  0.0  0.0  0.0  \n",
      "1518  0.0   0.0  0.00000  0.00000  0.000000  0.000000  0.0  0.0  0.0  \n",
      "1519  0.0   0.0  0.02827  0.02852  0.029962  0.000000  0.0  0.0  0.0  \n",
      "\n",
      "[1520 rows x 5000 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "Tfidf_vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(1, 5), max_df=1.0, min_df=1, max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "Tfidf_vec.fit(X_train)\n",
    "\n",
    "# Transform the training and test data\n",
    "train_features1 = Tfidf_vec.transform(X_train)\n",
    "test_features1 = Tfidf_vec.transform(X_test)\n",
    "\n",
    "# Display some information about the transformed data\n",
    "print(f\"Train features shape: {train_features1.shape}\")\n",
    "print(f\"Test features shape: {test_features1.shape}\")\n",
    "\n",
    "# Optional: Convert the transformed data to dense format and display it\n",
    "train_features_dense = train_features1.todense()\n",
    "test_features_dense = test_features1.todense()\n",
    "\n",
    "# Get the feature names (terms)\n",
    "feature_names = Tfidf_vec.get_feature_names()\n",
    "\n",
    "train_features_df = pd.DataFrame(train_features_dense, columns=feature_names)\n",
    "test_features_df = pd.DataFrame(test_features_dense, columns=feature_names)\n",
    "\n",
    "print(\"Train Features:\")\n",
    "print(train_features_df)\n",
    "print(\"Test Features:\")\n",
    "print(test_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea32887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

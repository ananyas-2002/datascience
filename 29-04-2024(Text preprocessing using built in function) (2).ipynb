{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b58c7f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\user\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b939013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.13)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from num2words) (0.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2d9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\User\\\\anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\~0ibs\\\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca41544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ba36e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_9608/2120401968.py:17: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import regex\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import demoji\n",
    "import emoji\n",
    "from sklearn.metrics import f1_score\n",
    "demoji.download_codes()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from num2words import num2words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fa8625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading whitespace: Package 'whitespace' not found\n",
      "[nltk_data]     in index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('whitespace')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14843ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972d3568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh   I don’t know about you Irvine b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>https://t.co/T2aD3v6dpm I bet money if i went...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh   I don’t know about you Irvine b...   \n",
       "1  1377631738692796417   https://t.co/T2aD3v6dpm I bet money if i went...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5  1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6  1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7  1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8  1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9  1362671045136809985  I’m going to sound like I have lost my marbles...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28097f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501112d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6266\n",
       "1    1334\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f57cc9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba92c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emot_object = emot.core.emot()\n",
    "ps =PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "exclude = set(string.punctuation)\n",
    "def preprocess(text):\n",
    "  #text=demoji.findall(df['Text'])\n",
    "  text = contractions.fix(text.lower(), slang=True)\n",
    "  #text= re.sub(r'\\d+', '', text)\n",
    "  text = re.sub(r'\\d+', lambda x: num2words(int(x.group(0))), text)\n",
    "  text=re.sub(r'@\\w+','',text)\n",
    "  text=re.sub(r'$', '', text)\n",
    "  text= re.sub(r'’','', text )  \n",
    "  text=re.sub('<.*?>','',text)\n",
    "  text=re.sub(r'http\\S+', '', text)\n",
    "  #text=emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "  text = ''.join(ch for ch in text if ch not in exclude)\n",
    "  tokens = word_tokenize(text)\n",
    "  #print(\"Tokens:\", tokens)\n",
    "  text = [t for t in tokens if t not in english_stopwords]\n",
    "  text = \" \".join(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf10dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "#import demoji\n",
    "\n",
    "#demoji.download_codes()\n",
    "def emo(text):\n",
    "  temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
    "  temp=temp.replace(\"_\",\"  \")\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c78f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emo']=data[\"text\"].apply(lambda x:emo(x))\n",
    "data[\"clean_text\"]=data['emo'].apply(lambda X: preprocess(X))\n",
    "#added_data[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3eb1c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh   I don’t know about you Irvine b...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh   I don’t know about you Irvine b...</td>\n",
       "      <td>know irvine keep told covid exist therefore do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>https://t.co/T2aD3v6dpm I bet money if i went...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://t.co/T2aD3v6dpm I bet money if i went...</td>\n",
       "      <td>bet money went n took covid test right going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>wife received positive covid test result despi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>one hundred eightyzero people two vaccine shot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>whole family sick af hospital heart palpitatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh   I don’t know about you Irvine b...   \n",
       "1  1377631738692796417   https://t.co/T2aD3v6dpm I bet money if i went...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "\n",
       "   label                                                emo  \\\n",
       "0      0  @IrvineWelsh   I don’t know about you Irvine b...   \n",
       "1      0   https://t.co/T2aD3v6dpm I bet money if i went...   \n",
       "2      0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3      0  Out of the 180,000+ people who have had the tw...   \n",
       "4      0  My whole family is sick af and here I am now i...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  know irvine keep told covid exist therefore do...  \n",
       "1  bet money went n took covid test right going t...  \n",
       "2  wife received positive covid test result despi...  \n",
       "3  one hundred eightyzero people two vaccine shot...  \n",
       "4  whole family sick af hospital heart palpitatio...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ef9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['clean_text'], data['label'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e845c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>1375556191900798982</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>0</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>twelve months know three people tested positiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7571</th>\n",
       "      <td>1386424325268557832</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>thousand one hundred eleven live state populat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>1381642657429082112</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>yupppp seen stroke patients fortys fiftys reha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>1377644044197752837</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>0</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>actually gym costs ten month way better equipm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>1375572937739210754</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>got second shot amp continue wear maskeven ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>1387648123246350338</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>went hospital yesterday chest pain got chest x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>1387906108514136066</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>0</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>well got second pfizer dose two weekends ago r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>1304095108862586880</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>0</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>last night reading fortysixyearold woman diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>1373826228105383937</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>1</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>weeks ago covid mild thankfully wife found got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>1349069842377187328</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>seeing members congress received first dose va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>1339654898904752128</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>0</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>scheduled covid vaccine monday currently round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>1374160581641527302</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>0</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>honest wearing mask whole time inlaws home saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>1375207369601257472</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>0</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>got close contact positive covid patient swab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>1373658117171507205</td>\n",
       "      <td>@Richard_Norfolk @jeremyhead i honestly don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Richard  Norfolk @jeremyhead i honestly don't...</td>\n",
       "      <td>norfolk honestly know would ask situ shift wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>1372713568660033541</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>patient icu next husband died today sad day fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>1382837701536227330</td>\n",
       "      <td>@Being_Melody My husband was sick after the fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Being  Melody My husband was sick after the f...</td>\n",
       "      <td>melody husband sick first shot think covid jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>1376381344775876610</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>1</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>top making work tested positive covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>1374910936356638725</td>\n",
       "      <td>@Clarja_wewon 1st shot: arm slightly sore duri...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Clarja  wewon 1st shot: arm slightly sore dur...</td>\n",
       "      <td>wewon onest shot arm slightly sore first night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>1353400480056172544</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>diagnosed covid send home without medication t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>1388623228030144513</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>1</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>really trust statistics put covid went er told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>1373904450126032896</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>0</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>covid vaccine seventytwo hours pcr test chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>1386302260414664708</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>goodmorning everyone apologize time away recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>1369334430582575109</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>ninetytwoyo lady used help look covid positive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>1381644471989895178</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>buddy sixtyeight shots really bad shape hospit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>1377831579922366465</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>damn found tested positive covid earlier today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...</td>\n",
       "      <td>one willing bet people could care less vaccine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>ended hospital fever broke sudden severe heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>know wife got market someone caring wear one k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>thousand three hundred eightyseven wonder coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>berwickbased clinical care assistant fiona mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "7570  1375556191900798982  In 12 months, I only know of 3 people who test...   \n",
       "7571  1386424325268557832  @anet2111 I live in a state with the populatio...   \n",
       "7572  1381642657429082112  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573  1377644044197752837  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574  1375572937739210754  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575  1387648123246350338  Went to hospital yesterday because I had some ...   \n",
       "7576  1387906108514136066  Well... I got my second Pfizer dose two weeken...   \n",
       "7577  1304095108862586880  last night, after reading about the 46-year-ol...   \n",
       "7578  1373826228105383937  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579  1349069842377187328  Seeing all these Members of Congress (who’ve a...   \n",
       "7580  1339654898904752128  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581  1374160581641527302  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582  1375207369601257472  I got in close contact with a positive covid p...   \n",
       "7583  1373658117171507205  @Richard_Norfolk @jeremyhead i honestly don't ...   \n",
       "7584  1372713568660033541  The patient in ICU next to my husband died tod...   \n",
       "7585  1382837701536227330  @Being_Melody My husband was sick after the fi...   \n",
       "7586  1376381344775876610  ON TOP of making me WORK tested positive for C...   \n",
       "7587  1374910936356638725  @Clarja_wewon 1st shot: arm slightly sore duri...   \n",
       "7588  1353400480056172544  If you're diagnosed with covid they send you h...   \n",
       "7589  1388623228030144513  i really don’t trust the statistics they put o...   \n",
       "7590  1373904450126032896  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591  1386302260414664708  Goodmorning everyone. I apologize for the time...   \n",
       "7592  1369334430582575109  A 92yo lady I used to help look after has had ...   \n",
       "7593  1381644471989895178  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594  1377831579922366465  Damn just found out I tested positive for Covi...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label                                                emo  \\\n",
       "7570      0  In 12 months, I only know of 3 people who test...   \n",
       "7571      0  @anet2111 I live in a state with the populatio...   \n",
       "7572      0  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573      0  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574      0  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575      1  Went to hospital yesterday because I had some ...   \n",
       "7576      0  Well... I got my second Pfizer dose two weeken...   \n",
       "7577      0  last night, after reading about the 46-year-ol...   \n",
       "7578      1  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579      0  Seeing all these Members of Congress (who’ve a...   \n",
       "7580      0  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581      0  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582      0  I got in close contact with a positive covid p...   \n",
       "7583      0  @Richard  Norfolk @jeremyhead i honestly don't...   \n",
       "7584      0  The patient in ICU next to my husband died tod...   \n",
       "7585      0  @Being  Melody My husband was sick after the f...   \n",
       "7586      1  ON TOP of making me WORK tested positive for C...   \n",
       "7587      0  @Clarja  wewon 1st shot: arm slightly sore dur...   \n",
       "7588      0  If you're diagnosed with covid they send you h...   \n",
       "7589      1  i really don’t trust the statistics they put o...   \n",
       "7590      0  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591      1  Goodmorning everyone. I apologize for the time...   \n",
       "7592      0  A 92yo lady I used to help look after has had ...   \n",
       "7593      0  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594      1  Damn just found out I tested positive for Covi...   \n",
       "7595      0  @galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...   \n",
       "7596      1  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597      0  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598      0  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599      0  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "                                             clean_text  \n",
       "7570  twelve months know three people tested positiv...  \n",
       "7571  thousand one hundred eleven live state populat...  \n",
       "7572  yupppp seen stroke patients fortys fiftys reha...  \n",
       "7573  actually gym costs ten month way better equipm...  \n",
       "7574  got second shot amp continue wear maskeven ful...  \n",
       "7575  went hospital yesterday chest pain got chest x...  \n",
       "7576  well got second pfizer dose two weekends ago r...  \n",
       "7577  last night reading fortysixyearold woman diagn...  \n",
       "7578  weeks ago covid mild thankfully wife found got...  \n",
       "7579  seeing members congress received first dose va...  \n",
       "7580  scheduled covid vaccine monday currently round...  \n",
       "7581  honest wearing mask whole time inlaws home saf...  \n",
       "7582  got close contact positive covid patient swab ...  \n",
       "7583  norfolk honestly know would ask situ shift wee...  \n",
       "7584  patient icu next husband died today sad day fa...  \n",
       "7585  melody husband sick first shot think covid jan...  \n",
       "7586              top making work tested positive covid  \n",
       "7587  wewon onest shot arm slightly sore first night...  \n",
       "7588  diagnosed covid send home without medication t...  \n",
       "7589  really trust statistics put covid went er told...  \n",
       "7590  covid vaccine seventytwo hours pcr test chance...  \n",
       "7591  goodmorning everyone apologize time away recen...  \n",
       "7592  ninetytwoyo lady used help look covid positive...  \n",
       "7593  buddy sixtyeight shots really bad shape hospit...  \n",
       "7594  damn found tested positive covid earlier today...  \n",
       "7595  one willing bet people could care less vaccine...  \n",
       "7596  ended hospital fever broke sudden severe heart...  \n",
       "7597  know wife got market someone caring wear one k...  \n",
       "7598  thousand three hundred eightyseven wonder coun...  \n",
       "7599  berwickbased clinical care assistant fiona mat...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fb628",
   "metadata": {},
   "source": [
    "# Feature Extraction: TF-IDF (char_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42715fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(1, 5), max_df=1.0, min_df=1, max_features=5000)\n",
    "count_train = Tfidf_vec.fit(X_train)\n",
    "train_features1 = Tfidf_vec.transform(X_train)\n",
    "test_features1 = Tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ac5ad",
   "metadata": {},
   "source": [
    "Feature Extraction- (word) TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab19b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " Tfidf_vec1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=1.0, min_df=1, max_features=5000)\n",
    " count_train1 = Tfidf_vec1.fit(X_train)\n",
    " train_features2= Tfidf_vec1.transform(X_train)\n",
    " test_features2 = Tfidf_vec1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3857a9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' a',\n",
       " ' ab',\n",
       " ' abl',\n",
       " ' able',\n",
       " ' ac',\n",
       " ' acc',\n",
       " ' act',\n",
       " ' actu',\n",
       " ' ad',\n",
       " ' adm',\n",
       " ' admi',\n",
       " ' af',\n",
       " ' ag',\n",
       " ' age',\n",
       " ' ago',\n",
       " ' ago ',\n",
       " ' al',\n",
       " ' all',\n",
       " ' alm',\n",
       " ' almo',\n",
       " ' alo',\n",
       " ' alon',\n",
       " ' alr',\n",
       " ' alre',\n",
       " ' als',\n",
       " ' also',\n",
       " ' am',\n",
       " ' ame',\n",
       " ' amp',\n",
       " ' amp ',\n",
       " ' an',\n",
       " ' ann',\n",
       " ' ano',\n",
       " ' anot',\n",
       " ' ant',\n",
       " ' anti',\n",
       " ' any',\n",
       " ' anyo',\n",
       " ' anyt',\n",
       " ' ap',\n",
       " ' app',\n",
       " ' apr',\n",
       " ' apri',\n",
       " ' ar',\n",
       " ' aro',\n",
       " ' arou',\n",
       " ' as',\n",
       " ' ask',\n",
       " ' ass',\n",
       " ' ast',\n",
       " ' at',\n",
       " ' att',\n",
       " ' au',\n",
       " ' av',\n",
       " ' aw',\n",
       " ' awa',\n",
       " ' away',\n",
       " ' b',\n",
       " ' ba',\n",
       " ' bac',\n",
       " ' back',\n",
       " ' bad',\n",
       " ' bad ',\n",
       " ' bas',\n",
       " ' be',\n",
       " ' bec',\n",
       " ' bed',\n",
       " ' bel',\n",
       " ' beli',\n",
       " ' bet',\n",
       " ' bett',\n",
       " ' bi',\n",
       " ' big',\n",
       " ' bit',\n",
       " ' bl',\n",
       " ' blo',\n",
       " ' bloo',\n",
       " ' bo',\n",
       " ' bod',\n",
       " ' br',\n",
       " ' bra',\n",
       " ' bre',\n",
       " ' brea',\n",
       " ' bri',\n",
       " ' bro',\n",
       " ' bu',\n",
       " ' c',\n",
       " ' ca',\n",
       " ' cal',\n",
       " ' call',\n",
       " ' cam',\n",
       " ' came',\n",
       " ' can',\n",
       " ' canc',\n",
       " ' car',\n",
       " ' care',\n",
       " ' cas',\n",
       " ' case',\n",
       " ' cat',\n",
       " ' catc',\n",
       " ' cau',\n",
       " ' caug',\n",
       " ' caus',\n",
       " ' ce',\n",
       " ' cer',\n",
       " ' cert',\n",
       " ' ch',\n",
       " ' cha',\n",
       " ' chan',\n",
       " ' che',\n",
       " ' chec',\n",
       " ' chi',\n",
       " ' chil',\n",
       " ' cho',\n",
       " ' chr',\n",
       " ' cl',\n",
       " ' cla',\n",
       " ' cle',\n",
       " ' clea',\n",
       " ' cli',\n",
       " ' clo',\n",
       " ' clos',\n",
       " ' co',\n",
       " ' col',\n",
       " ' cold',\n",
       " ' coll',\n",
       " ' com',\n",
       " ' come',\n",
       " ' comi',\n",
       " ' comm',\n",
       " ' comp',\n",
       " ' con',\n",
       " ' cond',\n",
       " ' conf',\n",
       " ' cons',\n",
       " ' cont',\n",
       " ' cor',\n",
       " ' coro',\n",
       " ' cou',\n",
       " ' coul',\n",
       " ' coun',\n",
       " ' coup',\n",
       " ' cov',\n",
       " ' covi',\n",
       " ' cr',\n",
       " ' cra',\n",
       " ' cry',\n",
       " ' cryi',\n",
       " ' cu',\n",
       " ' cur',\n",
       " ' curr',\n",
       " ' d',\n",
       " ' da',\n",
       " ' dam',\n",
       " ' dat',\n",
       " ' day',\n",
       " ' day ',\n",
       " ' days',\n",
       " ' de',\n",
       " ' dea',\n",
       " ' dead',\n",
       " ' deat',\n",
       " ' dec',\n",
       " ' dece',\n",
       " ' deci',\n",
       " ' def',\n",
       " ' dep',\n",
       " ' des',\n",
       " ' dev',\n",
       " ' di',\n",
       " ' dia',\n",
       " ' diag',\n",
       " ' die',\n",
       " ' die ',\n",
       " ' died',\n",
       " ' dif',\n",
       " ' diff',\n",
       " ' dis',\n",
       " ' dise',\n",
       " ' dist',\n",
       " ' do',\n",
       " ' doc',\n",
       " ' doct',\n",
       " ' don',\n",
       " ' done',\n",
       " ' dos',\n",
       " ' dose',\n",
       " ' dou',\n",
       " ' doub',\n",
       " ' dr',\n",
       " ' dr ',\n",
       " ' dri',\n",
       " ' du',\n",
       " ' due',\n",
       " ' due ',\n",
       " ' dy',\n",
       " ' dyi',\n",
       " ' dyin',\n",
       " ' e',\n",
       " ' ea',\n",
       " ' ear',\n",
       " ' earl',\n",
       " ' ef',\n",
       " ' eff',\n",
       " ' effe',\n",
       " ' ei',\n",
       " ' eig',\n",
       " ' eigh',\n",
       " ' eit',\n",
       " ' eith',\n",
       " ' el',\n",
       " ' ele',\n",
       " ' elev',\n",
       " ' els',\n",
       " ' else',\n",
       " ' em',\n",
       " ' en',\n",
       " ' end',\n",
       " ' end ',\n",
       " ' ende',\n",
       " ' eno',\n",
       " ' enou',\n",
       " ' ent',\n",
       " ' er',\n",
       " ' er ',\n",
       " ' es',\n",
       " ' ev',\n",
       " ' eve',\n",
       " ' even',\n",
       " ' ever',\n",
       " ' ex',\n",
       " ' exa',\n",
       " ' exc',\n",
       " ' exp',\n",
       " ' expe',\n",
       " ' expo',\n",
       " ' ext',\n",
       " ' ey',\n",
       " ' eye',\n",
       " ' eyes',\n",
       " ' f',\n",
       " ' fa',\n",
       " ' fac',\n",
       " ' face',\n",
       " ' fact',\n",
       " ' fai',\n",
       " ' fal',\n",
       " ' fals',\n",
       " ' fam',\n",
       " ' fami',\n",
       " ' far',\n",
       " ' far ',\n",
       " ' fe',\n",
       " ' fea',\n",
       " ' fear',\n",
       " ' fee',\n",
       " ' feel',\n",
       " ' fel',\n",
       " ' felt',\n",
       " ' fev',\n",
       " ' feve',\n",
       " ' fi',\n",
       " ' fif',\n",
       " ' fift',\n",
       " ' fig',\n",
       " ' figh',\n",
       " ' fin',\n",
       " ' fina',\n",
       " ' find',\n",
       " ' fine',\n",
       " ' fir',\n",
       " ' firs',\n",
       " ' fiv',\n",
       " ' five',\n",
       " ' fl',\n",
       " ' flo',\n",
       " ' flu',\n",
       " ' flu ',\n",
       " ' fo',\n",
       " ' fol',\n",
       " ' fold',\n",
       " ' foll',\n",
       " ' for',\n",
       " ' fort',\n",
       " ' fou',\n",
       " ' foun',\n",
       " ' four',\n",
       " ' fr',\n",
       " ' fre',\n",
       " ' free',\n",
       " ' fri',\n",
       " ' fro',\n",
       " ' fu',\n",
       " ' fuc',\n",
       " ' fuck',\n",
       " ' ful',\n",
       " ' full',\n",
       " ' fun',\n",
       " ' g',\n",
       " ' ga',\n",
       " ' ge',\n",
       " ' get',\n",
       " ' get ',\n",
       " ' gett',\n",
       " ' gi',\n",
       " ' giv',\n",
       " ' give',\n",
       " ' gl',\n",
       " ' go',\n",
       " ' go ',\n",
       " ' god',\n",
       " ' god ',\n",
       " ' goi',\n",
       " ' goin',\n",
       " ' goo',\n",
       " ' good',\n",
       " ' got',\n",
       " ' got ',\n",
       " ' gov',\n",
       " ' gove',\n",
       " ' gr',\n",
       " ' gra',\n",
       " ' gre',\n",
       " ' grea',\n",
       " ' gro',\n",
       " ' gu',\n",
       " ' gue',\n",
       " ' gues',\n",
       " ' guy',\n",
       " ' h',\n",
       " ' ha',\n",
       " ' hal',\n",
       " ' han',\n",
       " ' hand',\n",
       " ' hap',\n",
       " ' happ',\n",
       " ' har',\n",
       " ' hard',\n",
       " ' he',\n",
       " ' hea',\n",
       " ' head',\n",
       " ' heal',\n",
       " ' hear',\n",
       " ' hel',\n",
       " ' help',\n",
       " ' hi',\n",
       " ' hig',\n",
       " ' high',\n",
       " ' ho',\n",
       " ' hom',\n",
       " ' home',\n",
       " ' hop',\n",
       " ' hope',\n",
       " ' hos',\n",
       " ' hosp',\n",
       " ' hou',\n",
       " ' hour',\n",
       " ' hous',\n",
       " ' hu',\n",
       " ' hun',\n",
       " ' hund',\n",
       " ' hus',\n",
       " ' husb',\n",
       " ' i',\n",
       " ' ic',\n",
       " ' icu',\n",
       " ' icu ',\n",
       " ' id',\n",
       " ' il',\n",
       " ' ill',\n",
       " ' ill ',\n",
       " ' im',\n",
       " ' imm',\n",
       " ' immu',\n",
       " ' imp',\n",
       " ' in',\n",
       " ' inc',\n",
       " ' incl',\n",
       " ' ind',\n",
       " ' indi',\n",
       " ' inf',\n",
       " ' infe',\n",
       " ' ins',\n",
       " ' int',\n",
       " ' inte',\n",
       " ' is',\n",
       " ' iso',\n",
       " ' isol',\n",
       " ' iss',\n",
       " ' issu',\n",
       " ' it',\n",
       " ' j',\n",
       " ' ja',\n",
       " ' jab',\n",
       " ' jab ',\n",
       " ' jan',\n",
       " ' janu',\n",
       " ' jo',\n",
       " ' job',\n",
       " ' job ',\n",
       " ' joy',\n",
       " ' joy ',\n",
       " ' ju',\n",
       " ' k',\n",
       " ' ke',\n",
       " ' kee',\n",
       " ' keep',\n",
       " ' ki',\n",
       " ' kid',\n",
       " ' kids',\n",
       " ' kil',\n",
       " ' kill',\n",
       " ' kin',\n",
       " ' kn',\n",
       " ' kne',\n",
       " ' kno',\n",
       " ' know',\n",
       " ' l',\n",
       " ' la',\n",
       " ' las',\n",
       " ' last',\n",
       " ' lat',\n",
       " ' late',\n",
       " ' le',\n",
       " ' lea',\n",
       " ' leas',\n",
       " ' lef',\n",
       " ' left',\n",
       " ' les',\n",
       " ' less',\n",
       " ' let',\n",
       " ' let ',\n",
       " ' li',\n",
       " ' lif',\n",
       " ' life',\n",
       " ' lig',\n",
       " ' ligh',\n",
       " ' lik',\n",
       " ' like',\n",
       " ' lin',\n",
       " ' lis',\n",
       " ' list',\n",
       " ' lit',\n",
       " ' litt',\n",
       " ' liv',\n",
       " ' live',\n",
       " ' lo',\n",
       " ' loc',\n",
       " ' lock',\n",
       " ' lon',\n",
       " ' long',\n",
       " ' loo',\n",
       " ' look',\n",
       " ' los',\n",
       " ' lost',\n",
       " ' lot',\n",
       " ' lot ',\n",
       " ' lou',\n",
       " ' loud',\n",
       " ' lov',\n",
       " ' love',\n",
       " ' low',\n",
       " ' lu',\n",
       " ' luc',\n",
       " ' luck',\n",
       " ' lun',\n",
       " ' lung',\n",
       " ' m',\n",
       " ' ma',\n",
       " ' mad',\n",
       " ' made',\n",
       " ' mak',\n",
       " ' make',\n",
       " ' man',\n",
       " ' man ',\n",
       " ' many',\n",
       " ' mar',\n",
       " ' marc',\n",
       " ' mas',\n",
       " ' mask',\n",
       " ' mat',\n",
       " ' may',\n",
       " ' may ',\n",
       " ' mayb',\n",
       " ' me',\n",
       " ' mea',\n",
       " ' mean',\n",
       " ' med',\n",
       " ' medi',\n",
       " ' mem',\n",
       " ' memb',\n",
       " ' men',\n",
       " ' mi',\n",
       " ' mig',\n",
       " ' migh',\n",
       " ' mil',\n",
       " ' mild',\n",
       " ' mill',\n",
       " ' min',\n",
       " ' mis',\n",
       " ' mo',\n",
       " ' mod',\n",
       " ' mode',\n",
       " ' mon',\n",
       " ' mont',\n",
       " ' mor',\n",
       " ' morn',\n",
       " ' mu',\n",
       " ' muc',\n",
       " ' much',\n",
       " ' mum',\n",
       " ' mus',\n",
       " ' n',\n",
       " ' na',\n",
       " ' ne',\n",
       " ' nea',\n",
       " ' near',\n",
       " ' nee',\n",
       " ' need',\n",
       " ' neg',\n",
       " ' nega',\n",
       " ' nev',\n",
       " ' neve',\n",
       " ' new',\n",
       " ' new ',\n",
       " ' news',\n",
       " ' nex',\n",
       " ' next',\n",
       " ' nh',\n",
       " ' nhs',\n",
       " ' ni',\n",
       " ' nig',\n",
       " ' nigh',\n",
       " ' nin',\n",
       " ' nine',\n",
       " ' no',\n",
       " ' non',\n",
       " ' not',\n",
       " ' noth',\n",
       " ' nu',\n",
       " ' num',\n",
       " ' numb',\n",
       " ' nur',\n",
       " ' nurs',\n",
       " ' o',\n",
       " ' ob',\n",
       " ' of',\n",
       " ' off',\n",
       " ' offi',\n",
       " ' oh',\n",
       " ' oh ',\n",
       " ' ok',\n",
       " ' ok ',\n",
       " ' ol',\n",
       " ' old',\n",
       " ' old ',\n",
       " ' on',\n",
       " ' one',\n",
       " ' one ',\n",
       " ' ones',\n",
       " ' op',\n",
       " ' ope',\n",
       " ' open',\n",
       " ' or',\n",
       " ' ot',\n",
       " ' oth',\n",
       " ' othe',\n",
       " ' ou',\n",
       " ' out',\n",
       " ' ov',\n",
       " ' ove',\n",
       " ' over',\n",
       " ' ox',\n",
       " ' p',\n",
       " ' pa',\n",
       " ' pai',\n",
       " ' pain',\n",
       " ' pan',\n",
       " ' pand',\n",
       " ' par',\n",
       " ' part',\n",
       " ' pas',\n",
       " ' pass',\n",
       " ' past',\n",
       " ' pat',\n",
       " ' pati',\n",
       " ' pc',\n",
       " ' pcr',\n",
       " ' pcr ',\n",
       " ' pe',\n",
       " ' peo',\n",
       " ' peop',\n",
       " ' per',\n",
       " ' pers',\n",
       " ' pf',\n",
       " ' pfi',\n",
       " ' pfiz',\n",
       " ' ph',\n",
       " ' pi',\n",
       " ' pl',\n",
       " ' pla',\n",
       " ' play',\n",
       " ' ple',\n",
       " ' plea',\n",
       " ' pn',\n",
       " ' pne',\n",
       " ' pneu',\n",
       " ' po',\n",
       " ' poi',\n",
       " ' poin',\n",
       " ' pos',\n",
       " ' posi',\n",
       " ' poss',\n",
       " ' post',\n",
       " ' pr',\n",
       " ' pra',\n",
       " ' pray',\n",
       " ' pre',\n",
       " ' pres',\n",
       " ' pret',\n",
       " ' prev',\n",
       " ' pri',\n",
       " ' pro',\n",
       " ' prob',\n",
       " ' prot',\n",
       " ' prov',\n",
       " ' pu',\n",
       " ' put',\n",
       " ' put ',\n",
       " ' q',\n",
       " ' qu',\n",
       " ' qua',\n",
       " ' quar',\n",
       " ' que',\n",
       " ' ques',\n",
       " ' qui',\n",
       " ' r',\n",
       " ' ra',\n",
       " ' rat',\n",
       " ' rate',\n",
       " ' re',\n",
       " ' rea',\n",
       " ' reac',\n",
       " ' read',\n",
       " ' real',\n",
       " ' reas',\n",
       " ' rec',\n",
       " ' rece',\n",
       " ' reco',\n",
       " ' red',\n",
       " ' ref',\n",
       " ' refu',\n",
       " ' reg',\n",
       " ' rel',\n",
       " ' rela',\n",
       " ' rem',\n",
       " ' rep',\n",
       " ' repo',\n",
       " ' res',\n",
       " ' resp',\n",
       " ' rest',\n",
       " ' resu',\n",
       " ' ret',\n",
       " ' ri',\n",
       " ' rig',\n",
       " ' righ',\n",
       " ' ris',\n",
       " ' risk',\n",
       " ' ro',\n",
       " ' rol',\n",
       " ' roll',\n",
       " ' roo',\n",
       " ' room',\n",
       " ' ru',\n",
       " ' run',\n",
       " ' s',\n",
       " ' sa',\n",
       " ' sad',\n",
       " ' saf',\n",
       " ' safe',\n",
       " ' sai',\n",
       " ' said',\n",
       " ' saw',\n",
       " ' saw ',\n",
       " ' say',\n",
       " ' say ',\n",
       " ' sayi',\n",
       " ' says',\n",
       " ' sc',\n",
       " ' sca',\n",
       " ' scar',\n",
       " ' sch',\n",
       " ' scho',\n",
       " ' se',\n",
       " ' sec',\n",
       " ' seco',\n",
       " ' see',\n",
       " ' see ',\n",
       " ' seei',\n",
       " ' seem',\n",
       " ' seen',\n",
       " ' sel',\n",
       " ' sen',\n",
       " ' sent',\n",
       " ' ser',\n",
       " ' seri',\n",
       " ' sev',\n",
       " ' seve',\n",
       " ' sh',\n",
       " ' sha',\n",
       " ' shi',\n",
       " ' shit',\n",
       " ' sho',\n",
       " ' shot',\n",
       " ' show',\n",
       " ' si',\n",
       " ' sic',\n",
       " ' sick',\n",
       " ' sid',\n",
       " ' side',\n",
       " ' sig',\n",
       " ' sign',\n",
       " ' sin',\n",
       " ' sinc',\n",
       " ' sit',\n",
       " ' six',\n",
       " ' six ',\n",
       " ' sixt',\n",
       " ' sk',\n",
       " ' ski',\n",
       " ' skin',\n",
       " ' sl',\n",
       " ' sm',\n",
       " ' sme',\n",
       " ' smel',\n",
       " ' smi',\n",
       " ' smil',\n",
       " ' so',\n",
       " ' soc',\n",
       " ' soci',\n",
       " ' som',\n",
       " ' some',\n",
       " ' soo',\n",
       " ' soon',\n",
       " ' sor',\n",
       " ' sorr',\n",
       " ' sou',\n",
       " ' sp',\n",
       " ' spe',\n",
       " ' spen',\n",
       " ' spr',\n",
       " ' spre',\n",
       " ' st',\n",
       " ' sta',\n",
       " ' staf',\n",
       " ' star',\n",
       " ' stat',\n",
       " ' stay',\n",
       " ' ste',\n",
       " ' sti',\n",
       " ' stil',\n",
       " ' sto',\n",
       " ' stop',\n",
       " ' stor',\n",
       " ' str',\n",
       " ' stra',\n",
       " ' stre',\n",
       " ' stu',\n",
       " ' stud',\n",
       " ' su',\n",
       " ' suf',\n",
       " ' suff',\n",
       " ' sup',\n",
       " ' supp',\n",
       " ' sur',\n",
       " ' sure',\n",
       " ' surg',\n",
       " ' surv',\n",
       " ' sw',\n",
       " ' sy',\n",
       " ' sym',\n",
       " ' symp',\n",
       " ' sys',\n",
       " ' syst',\n",
       " ' t',\n",
       " ' ta',\n",
       " ' tak',\n",
       " ' take',\n",
       " ' taki',\n",
       " ' tal',\n",
       " ' talk',\n",
       " ' te',\n",
       " ' tea',\n",
       " ' tear',\n",
       " ' tel',\n",
       " ' tell',\n",
       " ' ten',\n",
       " ' ten ',\n",
       " ' ter',\n",
       " ' term',\n",
       " ' tes',\n",
       " ' test',\n",
       " ' th',\n",
       " ' tha',\n",
       " ' than',\n",
       " ' the',\n",
       " ' thi',\n",
       " ' thin',\n",
       " ' thir',\n",
       " ' tho',\n",
       " ' thou',\n",
       " ' thr',\n",
       " ' thre',\n",
       " ' thu',\n",
       " ' ti',\n",
       " ' tim',\n",
       " ' time',\n",
       " ' to',\n",
       " ' tod',\n",
       " ' toda',\n",
       " ' tol',\n",
       " ' told',\n",
       " ' ton',\n",
       " ' tone',\n",
       " ' too',\n",
       " ' took',\n",
       " ' tr',\n",
       " ' tra',\n",
       " ' tre',\n",
       " ' trea',\n",
       " ' tri',\n",
       " ' tria',\n",
       " ' tru',\n",
       " ' trum',\n",
       " ' try',\n",
       " ' tryi',\n",
       " ' tu',\n",
       " ' tur',\n",
       " ' turn',\n",
       " ' tw',\n",
       " ' twe',\n",
       " ' twel',\n",
       " ' twen',\n",
       " ' twi',\n",
       " ' two',\n",
       " ' two ',\n",
       " ' twon',\n",
       " ' u',\n",
       " ' un',\n",
       " ' und',\n",
       " ' unde',\n",
       " ' uni',\n",
       " ' up',\n",
       " ' ups',\n",
       " ' us',\n",
       " ' us ',\n",
       " ' use',\n",
       " ' use ',\n",
       " ' v',\n",
       " ' va',\n",
       " ' vac',\n",
       " ' vacc',\n",
       " ' var',\n",
       " ' vax',\n",
       " ' ve',\n",
       " ' ven',\n",
       " ' vent',\n",
       " ' vi',\n",
       " ' vir',\n",
       " ' viru',\n",
       " ' vis',\n",
       " ' visi',\n",
       " ' vo',\n",
       " ' w',\n",
       " ' w ',\n",
       " ' wa',\n",
       " ' wai',\n",
       " ' wait',\n",
       " ' wal',\n",
       " ' wan',\n",
       " ' want',\n",
       " ' war',\n",
       " ' wat',\n",
       " ' watc',\n",
       " ' way',\n",
       " ' way ',\n",
       " ' we',\n",
       " ' wea',\n",
       " ' wear',\n",
       " ' wee',\n",
       " ' week',\n",
       " ' wel',\n",
       " ' well',\n",
       " ' wen',\n",
       " ' went',\n",
       " ' wh',\n",
       " ' who',\n",
       " ' whol',\n",
       " ' wi',\n",
       " ' wif',\n",
       " ' wife',\n",
       " ' wis',\n",
       " ' wish',\n",
       " ' wit',\n",
       " ' with',\n",
       " ' wo',\n",
       " ' wom',\n",
       " ' woma',\n",
       " ' won',\n",
       " ' wond',\n",
       " ' wor',\n",
       " ' work',\n",
       " ' worr',\n",
       " ' wors',\n",
       " ' wou',\n",
       " ' woul',\n",
       " ' wr',\n",
       " ' wro',\n",
       " ' x',\n",
       " ' y',\n",
       " ' ye',\n",
       " ' yea',\n",
       " ' year',\n",
       " ' yes',\n",
       " ' yes ',\n",
       " ' yest',\n",
       " ' yet',\n",
       " ' yet ',\n",
       " ' yo',\n",
       " ' you',\n",
       " ' youn',\n",
       " ' z',\n",
       " ' ze',\n",
       " ' zer',\n",
       " ' zero',\n",
       " ' “',\n",
       " ' “ ',\n",
       " ' ”',\n",
       " ' ” ',\n",
       " 'a',\n",
       " 'a ',\n",
       " 'ab',\n",
       " 'ab ',\n",
       " 'abl',\n",
       " 'able',\n",
       " 'able ',\n",
       " 'ably',\n",
       " 'ably ',\n",
       " 'abs',\n",
       " 'ac',\n",
       " 'acc',\n",
       " 'acci',\n",
       " 'accin',\n",
       " 'ace',\n",
       " 'ace ',\n",
       " 'ach',\n",
       " 'ache',\n",
       " 'aci',\n",
       " 'ack',\n",
       " 'ack ',\n",
       " 'act',\n",
       " 'act ',\n",
       " 'acte',\n",
       " 'acti',\n",
       " 'actio',\n",
       " 'actu',\n",
       " 'actua',\n",
       " 'ad',\n",
       " 'ad ',\n",
       " 'ada',\n",
       " 'add',\n",
       " 'ade',\n",
       " 'ade ',\n",
       " 'adi',\n",
       " 'adin',\n",
       " 'ading',\n",
       " 'adl',\n",
       " 'adm',\n",
       " 'admi',\n",
       " 'admit',\n",
       " 'ady',\n",
       " 'ady ',\n",
       " 'af',\n",
       " 'afe',\n",
       " 'afe ',\n",
       " 'aff',\n",
       " 'aff ',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'age ',\n",
       " 'agi',\n",
       " 'agin',\n",
       " 'agn',\n",
       " 'agno',\n",
       " 'agnos',\n",
       " 'ago',\n",
       " 'ago ',\n",
       " 'agr',\n",
       " 'agre',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f21655",
   "metadata": {},
   "source": [
    "# Model Building with SVM - LinearSVC-TF-IDF-char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c335dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.1866\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      2040\n",
      "           1       0.46      0.70      0.56       468\n",
      "\n",
      "    accuracy                           0.79      2508\n",
      "   macro avg       0.69      0.76      0.71      2508\n",
      "weighted avg       0.84      0.79      0.81      2508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features1, y_train)\n",
    "y_pred1=clf1.predict(test_features1)\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23c6e6",
   "metadata": {},
   "source": [
    "# Model Building with SVM - LinearSVC-TF-IDF-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63115349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.2998\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88      2040\n",
      "           1       0.50      0.62      0.55       468\n",
      "\n",
      "    accuracy                           0.81      2508\n",
      "   macro avg       0.70      0.74      0.72      2508\n",
      "weighted avg       0.83      0.81      0.82      2508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features2, y_train)\n",
    "y_pred2=clf1.predict(test_features2)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4f791",
   "metadata": {},
   "source": [
    "# Feature Extraction: count vectorizer(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55f19c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(analyzer='char_wb', ngram_range=(1, 5), max_df=1.0, min_df=1, max_features=5000)\n",
    "count_train = count_vec.fit(X_train)\n",
    "train_features3 = count_vec.transform(X_train)\n",
    "test_features3 = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15c3df",
   "metadata": {},
   "source": [
    "# Feature Extraction: count vectorizer(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bb71301",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec1 = CountVectorizer(analyzer='word', ngram_range=(1, 3), max_df=1.0, min_df=1, max_features=5000)\n",
    "count_train = count_vec1.fit(X_train)\n",
    "train_features4 = count_vec1.transform(X_train)\n",
    "test_features4 = count_vec1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d561d",
   "metadata": {},
   "source": [
    "# Model Building with SVM - LinearSVC-CountVectorizer-char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "476b4bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.7448\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      2040\n",
      "           1       0.46      0.50      0.48       468\n",
      "\n",
      "    accuracy                           0.80      2508\n",
      "   macro avg       0.67      0.68      0.68      2508\n",
      "weighted avg       0.80      0.80      0.80      2508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features3, y_train)\n",
    "y_pred1=clf1.predict(test_features3)\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea513b4e",
   "metadata": {},
   "source": [
    "# Model Building with SVM - LinearSVC-CountVectorizer-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fea0c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.2632\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2040\n",
      "           1       0.47      0.51      0.49       468\n",
      "\n",
      "    accuracy                           0.80      2508\n",
      "   macro avg       0.68      0.69      0.69      2508\n",
      "weighted avg       0.81      0.80      0.81      2508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features4, y_train)\n",
    "y_pred2=clf1.predict(test_features4)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42930014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

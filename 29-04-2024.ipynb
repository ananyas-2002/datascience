{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58c7f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b939013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=c67345b562b0d0187dc721b6ed41d65ee5572a35a83d86b70ee2ed1c1238e92d\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba36e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_10172/424883077.py:17: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import regex\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import demoji\n",
    "import emoji\n",
    "from sklearn.metrics import f1_score\n",
    "demoji.download_codes()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fa8625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading whitespace: Package 'whitespace' not found\n",
      "[nltk_data]     in index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('whitespace')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14843ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972d3568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1  1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5  1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6  1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7  1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8  1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9  1362671045136809985  I’m going to sound like I have lost my marbles...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28097f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501112d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6266\n",
       "1    1334\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f57cc9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba92c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emot_object = emot.core.emot()\n",
    "ps =PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "exclude = set(string.punctuation)\n",
    "def preprocess(text):\n",
    "  #text=demoji.findall(df['Text'])\n",
    "  text = contractions.fix(text.lower(), slang=True)\n",
    "  #text= re.sub(r'\\d+', '', text)\n",
    "  text = re.sub(r'\\d+', lambda x: num2words(int(x.group(0))), text)\n",
    "  text=re.sub(r'$', '', text)\n",
    "  text= re.sub(r'’','', text )  \n",
    "  text=re.sub('<.*?>','',text)\n",
    "  text=re.sub(r'http\\S+', '', text)\n",
    "  #text=emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "  text = ''.join(ch for ch in text if ch not in exclude)\n",
    "  tokens = word_tokenize(text)\n",
    "  #print(\"Tokens:\", tokens)\n",
    "  text = [t for t in tokens if t not in english_stopwords]\n",
    "  text = \" \".join(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf10dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "#import demoji\n",
    "\n",
    "#demoji.download_codes()\n",
    "def emo(text):\n",
    "  temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
    "  temp=temp.replace(\"_\",\"  \")\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c78f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emo']=data[\"text\"].apply(lambda x:emo(x))\n",
    "data[\"clean_text\"]=data['emo'].apply(lambda X: preprocess(X))\n",
    "#added_data[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3eb1c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>irvinewelsh know irvine keep told covid exist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>bet money went n took covid test right going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>jamesmelville wife received positive covid tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>one hundred eightyzero people two vaccine shot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>whole family sick af hospital heart palpitatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1  1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "\n",
       "   label                                                emo  \\\n",
       "0      0  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1      0  I bet money if i went n took a covid test righ...   \n",
       "2      0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3      0  Out of the 180,000+ people who have had the tw...   \n",
       "4      0  My whole family is sick af and here I am now i...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  irvinewelsh know irvine keep told covid exist ...  \n",
       "1  bet money went n took covid test right going t...  \n",
       "2  jamesmelville wife received positive covid tes...  \n",
       "3  one hundred eightyzero people two vaccine shot...  \n",
       "4  whole family sick af hospital heart palpitatio...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ef9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['clean_text'], data['label'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e845c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>1375556191900798982</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>0</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>twelve months know three people tested positiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7571</th>\n",
       "      <td>1386424325268557832</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>anettwo thousand one hundred eleven live state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>1381642657429082112</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>yupppp seen stroke patients fortys fiftys reha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>1377644044197752837</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>0</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>evelkneidel actually gym costs ten month way b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>1375572937739210754</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>annabkrr got second shot amp continue wear mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>1387648123246350338</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>went hospital yesterday chest pain got chest x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>1387906108514136066</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>0</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>well got second pfizer dose two weekends ago r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>1304095108862586880</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>0</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>last night reading fortysixyearold woman diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>1373826228105383937</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>1</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>weeks ago covid mild thankfully wife found got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>1349069842377187328</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>seeing members congress received first dose va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>1339654898904752128</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>0</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>scheduled covid vaccine monday currently round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>1374160581641527302</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>0</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>sherilocascio honest wearing mask whole time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>1375207369601257472</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>0</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>got close contact positive covid patient swab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>1373658117171507205</td>\n",
       "      <td>@Richard_Norfolk @jeremyhead i honestly don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Richard  Norfolk @jeremyhead i honestly don't...</td>\n",
       "      <td>richard norfolk jeremyhead honestly know would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>1372713568660033541</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>patient icu next husband died today sad day fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>1382837701536227330</td>\n",
       "      <td>@Being_Melody My husband was sick after the fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Being  Melody My husband was sick after the f...</td>\n",
       "      <td>melody husband sick first shot think covid jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>1376381344775876610</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>1</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>top making work tested positive covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>1374910936356638725</td>\n",
       "      <td>@Clarja_wewon 1st shot: arm slightly sore duri...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Clarja  wewon 1st shot: arm slightly sore dur...</td>\n",
       "      <td>clarja wewon onest shot arm slightly sore firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>1353400480056172544</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>diagnosed covid send home without medication t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>1388623228030144513</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>1</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>really trust statistics put covid went er told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>1373904450126032896</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>0</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>covid vaccine seventytwo hours pcr test chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>1386302260414664708</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>goodmorning everyone apologize time away recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>1369334430582575109</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>ninetytwoyo lady used help look covid positive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>1381644471989895178</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>cbsnews cbseveningnews buddy sixtyeight shots ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>1377831579922366465</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>damn found tested positive covid earlier today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...</td>\n",
       "      <td>galaflux efb one drjekyllhjseven drleanawen wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>tabbattales nursekelsey ended hospital fever b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>unrealjust recdna cdcgov know wife got market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>angelafourteen thousand three hundred eightyse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>berwickbased clinical care assistant fiona mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "7570  1375556191900798982  In 12 months, I only know of 3 people who test...   \n",
       "7571  1386424325268557832  @anet2111 I live in a state with the populatio...   \n",
       "7572  1381642657429082112  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573  1377644044197752837  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574  1375572937739210754  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575  1387648123246350338  Went to hospital yesterday because I had some ...   \n",
       "7576  1387906108514136066  Well... I got my second Pfizer dose two weeken...   \n",
       "7577  1304095108862586880  last night, after reading about the 46-year-ol...   \n",
       "7578  1373826228105383937  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579  1349069842377187328  Seeing all these Members of Congress (who’ve a...   \n",
       "7580  1339654898904752128  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581  1374160581641527302  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582  1375207369601257472  I got in close contact with a positive covid p...   \n",
       "7583  1373658117171507205  @Richard_Norfolk @jeremyhead i honestly don't ...   \n",
       "7584  1372713568660033541  The patient in ICU next to my husband died tod...   \n",
       "7585  1382837701536227330  @Being_Melody My husband was sick after the fi...   \n",
       "7586  1376381344775876610  ON TOP of making me WORK tested positive for C...   \n",
       "7587  1374910936356638725  @Clarja_wewon 1st shot: arm slightly sore duri...   \n",
       "7588  1353400480056172544  If you're diagnosed with covid they send you h...   \n",
       "7589  1388623228030144513  i really don’t trust the statistics they put o...   \n",
       "7590  1373904450126032896  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591  1386302260414664708  Goodmorning everyone. I apologize for the time...   \n",
       "7592  1369334430582575109  A 92yo lady I used to help look after has had ...   \n",
       "7593  1381644471989895178  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594  1377831579922366465  Damn just found out I tested positive for Covi...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label                                                emo  \\\n",
       "7570      0  In 12 months, I only know of 3 people who test...   \n",
       "7571      0  @anet2111 I live in a state with the populatio...   \n",
       "7572      0  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573      0  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574      0  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575      1  Went to hospital yesterday because I had some ...   \n",
       "7576      0  Well... I got my second Pfizer dose two weeken...   \n",
       "7577      0  last night, after reading about the 46-year-ol...   \n",
       "7578      1  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579      0  Seeing all these Members of Congress (who’ve a...   \n",
       "7580      0  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581      0  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582      0  I got in close contact with a positive covid p...   \n",
       "7583      0  @Richard  Norfolk @jeremyhead i honestly don't...   \n",
       "7584      0  The patient in ICU next to my husband died tod...   \n",
       "7585      0  @Being  Melody My husband was sick after the f...   \n",
       "7586      1  ON TOP of making me WORK tested positive for C...   \n",
       "7587      0  @Clarja  wewon 1st shot: arm slightly sore dur...   \n",
       "7588      0  If you're diagnosed with covid they send you h...   \n",
       "7589      1  i really don’t trust the statistics they put o...   \n",
       "7590      0  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591      1  Goodmorning everyone. I apologize for the time...   \n",
       "7592      0  A 92yo lady I used to help look after has had ...   \n",
       "7593      0  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594      1  Damn just found out I tested positive for Covi...   \n",
       "7595      0  @galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...   \n",
       "7596      1  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597      0  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598      0  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599      0  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "                                             clean_text  \n",
       "7570  twelve months know three people tested positiv...  \n",
       "7571  anettwo thousand one hundred eleven live state...  \n",
       "7572  yupppp seen stroke patients fortys fiftys reha...  \n",
       "7573  evelkneidel actually gym costs ten month way b...  \n",
       "7574  annabkrr got second shot amp continue wear mas...  \n",
       "7575  went hospital yesterday chest pain got chest x...  \n",
       "7576  well got second pfizer dose two weekends ago r...  \n",
       "7577  last night reading fortysixyearold woman diagn...  \n",
       "7578  weeks ago covid mild thankfully wife found got...  \n",
       "7579  seeing members congress received first dose va...  \n",
       "7580  scheduled covid vaccine monday currently round...  \n",
       "7581  sherilocascio honest wearing mask whole time i...  \n",
       "7582  got close contact positive covid patient swab ...  \n",
       "7583  richard norfolk jeremyhead honestly know would...  \n",
       "7584  patient icu next husband died today sad day fa...  \n",
       "7585  melody husband sick first shot think covid jan...  \n",
       "7586              top making work tested positive covid  \n",
       "7587  clarja wewon onest shot arm slightly sore firs...  \n",
       "7588  diagnosed covid send home without medication t...  \n",
       "7589  really trust statistics put covid went er told...  \n",
       "7590  covid vaccine seventytwo hours pcr test chance...  \n",
       "7591  goodmorning everyone apologize time away recen...  \n",
       "7592  ninetytwoyo lady used help look covid positive...  \n",
       "7593  cbsnews cbseveningnews buddy sixtyeight shots ...  \n",
       "7594  damn found tested positive covid earlier today...  \n",
       "7595  galaflux efb one drjekyllhjseven drleanawen wi...  \n",
       "7596  tabbattales nursekelsey ended hospital fever b...  \n",
       "7597  unrealjust recdna cdcgov know wife got market ...  \n",
       "7598  angelafourteen thousand three hundred eightyse...  \n",
       "7599  berwickbased clinical care assistant fiona mat...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fb628",
   "metadata": {},
   "source": [
    "# Feature Extraction: TF-IDF (char_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42715fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(1, 5), max_df=1.0, min_df=1, max_features=5000)\n",
    "count_train = Tfidf_vec.fit(X_train)\n",
    "train_features1 = Tfidf_vec.transform(X_train)\n",
    "test_features1 = Tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ac5ad",
   "metadata": {},
   "source": [
    "Feature Extraction- (word) TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab19b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " Tfidf_vec1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=1.0, min_df=1, max_features=5000)\n",
    " count_train1 = Tfidf_vec1.fit(X_train)\n",
    " train_features2= Tfidf_vec1.transform(X_train)\n",
    " test_features2 = Tfidf_vec1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d561d",
   "metadata": {},
   "source": [
    "# Model Building with SVM - LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476b4bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.8644\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      2040\n",
      "           1       0.47      0.69      0.56       468\n",
      "\n",
      "    accuracy                           0.80      2508\n",
      "   macro avg       0.70      0.76      0.72      2508\n",
      "weighted avg       0.84      0.80      0.81      2508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features1, y_train)\n",
    "y_pred1=clf1.predict(test_features1)\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fea0c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.7783\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88      2040\n",
      "           1       0.51      0.63      0.57       468\n",
      "\n",
      "    accuracy                           0.82      2508\n",
      "   macro avg       0.71      0.75      0.72      2508\n",
      "weighted avg       0.84      0.82      0.83      2508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 =LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=10000, random_state=123)\n",
    "clf1.fit(train_features2, y_train)\n",
    "y_pred2=clf1.predict(test_features2)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Test Accuracy:\", round(accuracy*100, 4))\n",
    "\n",
    "print(\"\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42930014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

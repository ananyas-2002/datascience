{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2892a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of instances: 5\n",
      "Enter the number of attributes (including class label): 2\n",
      "Enter instances in the format 'attribute1 attribute2 ... class_label'\n",
      "0 A\n",
      "0 A\n",
      "0 A\n",
      "1 B\n",
      "1 B\n",
      "Enter the index of the attribute for which you want to calculate information gain: 0\n",
      "Information Gain for attribute 0 : 0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import log2\n",
    "\n",
    "def entropy(data):\n",
    "    # Calculate the entropy of a dataset\n",
    "    classes, counts = np.unique(data, return_counts=True)\n",
    "    probs = counts / len(data)\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, attribute_index):\n",
    "    # Calculate the information gain of an attribute in a dataset\n",
    "    total_entropy = entropy(data[:, -1])  # Calculate the entropy of the entire dataset\n",
    "    attribute_values, counts = np.unique(data[:, attribute_index], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for value, count in zip(attribute_values, counts):\n",
    "        subset = data[data[:, attribute_index] == value]\n",
    "        subset_entropy = entropy(subset[:, -1])\n",
    "        weighted_entropy += (count / len(data)) * subset_entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def calculate_information_gain(dataset, attribute_index):\n",
    "    # Convert dataset to numpy array if it's not already\n",
    "    data = np.array(dataset)\n",
    "    return information_gain(data, attribute_index)\n",
    "\n",
    "# Accept user input for dataset\n",
    "data = []\n",
    "num_instances = int(input(\"Enter the number of instances: \"))\n",
    "num_attributes = int(input(\"Enter the number of attributes (including class label): \"))\n",
    "print(\"Enter instances in the format 'attribute1 attribute2 ... class_label'\")\n",
    "for _ in range(num_instances):\n",
    "    instance = input().strip().split()\n",
    "    data.append(instance)\n",
    "\n",
    "# Accept user input for attribute index\n",
    "attribute_index = int(input(\"Enter the index of the attribute for which you want to calculate information gain: \"))\n",
    "\n",
    "# Calculating information gain\n",
    "ig = calculate_information_gain(data, attribute_index)\n",
    "print(\"Information Gain for attribute\", attribute_index, \":\", ig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c23274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of instances: 5\n",
      "Enter the number of attributes (including class label): 2\n",
      "Enter instances in the format 'attribute1 attribute2 ... class_label'\n",
      "1 a\n",
      "1 a\n",
      "0 b\n",
      "0 b\n",
      "0 b\n",
      "Enter the index of the attribute for which you want to calculate Gini index: 0\n",
      "Gini index for attribute 0 : 0.0\n"
     ]
    }
   ],
   "source": [
    "#gini index\n",
    "import numpy as np\n",
    "\n",
    "def gini_index(data):\n",
    "    # Calculate the Gini index of a dataset\n",
    "    class_labels = data[:, -1]\n",
    "    total_instances = len(class_labels)\n",
    "    label_counts = np.unique(class_labels, return_counts=True)[1]\n",
    "    label_probabilities = label_counts / total_instances\n",
    "    gini = 1 - np.sum(label_probabilities**2)\n",
    "    return gini\n",
    "\n",
    "def gini_index_attribute(data, attribute_index):\n",
    "    # Calculate the Gini index of an attribute in a dataset\n",
    "    attribute_values = np.unique(data[:, attribute_index])\n",
    "    total_instances = len(data)\n",
    "    gini_attribute = 0\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[:, attribute_index] == value]\n",
    "        subset_instances = len(subset)\n",
    "        gini_subset = gini_index(subset)\n",
    "        gini_attribute += (subset_instances / total_instances) * gini_subset\n",
    "    return gini_attribute\n",
    "\n",
    "# Accept user input for dataset\n",
    "data = []\n",
    "num_instances = int(input(\"Enter the number of instances: \"))\n",
    "num_attributes = int(input(\"Enter the number of attributes (including class label): \"))\n",
    "print(\"Enter instances in the format 'attribute1 attribute2 ... class_label'\")\n",
    "for _ in range(num_instances):\n",
    "    instance = input().strip().split()\n",
    "    data.append(instance)\n",
    "\n",
    "# Convert dataset to numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# Accept user input for attribute index\n",
    "attribute_index = int(input(\"Enter the index of the attribute for which you want to calculate Gini index: \"))\n",
    "\n",
    "# Calculating Gini index for the specified attribute\n",
    "gini_attr = gini_index_attribute(data, attribute_index)\n",
    "print(\"Gini index for attribute\", attribute_index, \":\", gini_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0583e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of instances: 3\n",
      "Enter the number of attributes: 2\n",
      "Enter instances in the format 'attribute1 attribute2 ...'\n",
      "1.0 2.0\n",
      "2.0 3.0\n",
      "3.0 4.0\n",
      "Select a distance measure:\n",
      "1. Euclidean\n",
      "2. Manhattan\n",
      "3. Cosine Similarity\n",
      "Enter the index of the distance measure: 1\n",
      "Enter two instances:\n",
      "1.0 2.0\n",
      "2.0 2.0\n",
      "Distance between the two instances using Euclidean: 1.0\n"
     ]
    }
   ],
   "source": [
    "#different distance measures\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(instance1, instance2):\n",
    "    # Calculate the Euclidean distance between two instances\n",
    "    return np.linalg.norm(instance1 - instance2)\n",
    "\n",
    "def manhattan_distance(instance1, instance2):\n",
    "    # Calculate the Manhattan distance between two instances\n",
    "    return np.sum(np.abs(instance1 - instance2))\n",
    "\n",
    "def cosine_similarity(instance1, instance2):\n",
    "    # Calculate the Cosine similarity between two instances\n",
    "    dot_product = np.dot(instance1, instance2)\n",
    "    norm1 = np.linalg.norm(instance1)\n",
    "    norm2 = np.linalg.norm(instance2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Dictionary to map distance measure names to their respective functions\n",
    "distance_measures = {\n",
    "    \"Euclidean\": euclidean_distance,\n",
    "    \"Manhattan\": manhattan_distance,\n",
    "    \"Cosine Similarity\": cosine_similarity\n",
    "}\n",
    "\n",
    "# Accept user input for dataset\n",
    "data = []\n",
    "num_instances = int(input(\"Enter the number of instances: \"))\n",
    "num_attributes = int(input(\"Enter the number of attributes: \"))\n",
    "print(\"Enter instances in the format 'attribute1 attribute2 ...'\")\n",
    "for _ in range(num_instances):\n",
    "    instance = list(map(float, input().strip().split()))\n",
    "    data.append(instance)\n",
    "\n",
    "# Convert dataset to numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# Accept user input for selecting distance measure\n",
    "print(\"Select a distance measure:\")\n",
    "for i, measure in enumerate(distance_measures.keys()):\n",
    "    print(f\"{i+1}. {measure}\")\n",
    "selected_measure_index = int(input(\"Enter the index of the distance measure: \")) - 1\n",
    "\n",
    "# Select the distance measure function based on user input\n",
    "selected_measure = list(distance_measures.values())[selected_measure_index]\n",
    "\n",
    "# Accept user input for two instances\n",
    "print(\"Enter two instances:\")\n",
    "instance1 = np.array(list(map(float, input().strip().split())))\n",
    "instance2 = np.array(list(map(float, input().strip().split())))\n",
    "\n",
    "# Calculate and print the distance between the two instances using the selected measure\n",
    "distance = selected_measure(instance1, instance2)\n",
    "print(f\"Distance between the two instances using {list(distance_measures.keys())[selected_measure_index]}: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78fb5681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of input neurons: 2\n",
      "Enter the number of hidden neurons: 2\n",
      "Enter the number of output neurons: 1\n",
      "Enter the number of training instances: 4\n",
      "Enter 4 training instances in the format 'input1 input2 ... output1 output2 ...'\n",
      "0 0 0\n",
      "0 1 1\n",
      "1 0 1\n",
      "1 1 1\n",
      "Enter the number of epochs: 10000\n",
      "Enter the learning rate: 0.1\n",
      "Predictions after training:\n",
      "Input: [0. 0.], Predicted output: [0.06699023]\n",
      "Input: [0. 1.], Predicted output: [0.96474803]\n",
      "Input: [1. 0.], Predicted output: [0.96519432]\n",
      "Input: [1. 1.], Predicted output: [0.97925402]\n"
     ]
    }
   ],
   "source": [
    "#backpropogation\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden)\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "        self.output = sigmoid(np.dot(self.hidden_output, self.weights_hidden_output))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        # Backpropagation\n",
    "        error = y - output\n",
    "        d_output = error * sigmoid_derivative(output)\n",
    "        \n",
    "        error_hidden = np.dot(d_output, self.weights_hidden_output.T)\n",
    "        d_hidden = error_hidden * sigmoid_derivative(self.hidden_output)\n",
    "        \n",
    "        # Update weights\n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, d_output) * learning_rate\n",
    "        self.weights_input_hidden += np.dot(X.T, d_hidden) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            output = self.forward(X)\n",
    "            \n",
    "            # Backpropagation\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "\n",
    "# Accept user input for network architecture\n",
    "input_size = int(input(\"Enter the number of input neurons: \"))\n",
    "hidden_size = int(input(\"Enter the number of hidden neurons: \"))\n",
    "output_size = int(input(\"Enter the number of output neurons: \"))\n",
    "\n",
    "# Initialize neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Accept user input for training data\n",
    "num_instances = int(input(\"Enter the number of training instances: \"))\n",
    "X = np.zeros((num_instances, input_size))\n",
    "y = np.zeros((num_instances, output_size))\n",
    "print(f\"Enter {num_instances} training instances in the format 'input1 input2 ... output1 output2 ...'\")\n",
    "for i in range(num_instances):\n",
    "    instance = list(map(float, input().strip().split()))\n",
    "    X[i] = instance[:input_size]\n",
    "    y[i] = instance[input_size:]\n",
    "\n",
    "# Accept user input for training parameters\n",
    "epochs = int(input(\"Enter the number of epochs: \"))\n",
    "learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "# Train neural network\n",
    "nn.train(X, y, epochs, learning_rate)\n",
    "\n",
    "# Test the trained model\n",
    "print(\"Predictions after training:\")\n",
    "for i in range(len(X)):\n",
    "    prediction = nn.forward(X[i])\n",
    "    print(f\"Input: {X[i]}, Predicted output: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e9ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
